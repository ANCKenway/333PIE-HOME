# ğŸ§ª Tests et Validation 333HOME

## ğŸ¯ Objectif
Guide complet pour tester et valider toutes les fonctionnalitÃ©s de 333HOME aprÃ¨s la refactorisation modulaire.

---

## ğŸ“‹ StratÃ©gie de Test

### ğŸª Types de Tests
1. **Tests unitaires** : Modules individuels
2. **Tests d'intÃ©gration** : API endpoints
3. **Tests E2E** : Interface utilisateur
4. **Tests de performance** : Charge et vitesse
5. **Tests sÃ©curitÃ©** : VulnÃ©rabilitÃ©s

### ğŸ¯ Objectifs QualitÃ©
- **Couverture** : 80%+ du code critique
- **Performance** : < 2s rÃ©ponse API
- **DisponibilitÃ©** : 99%+ uptime
- **SÃ©curitÃ©** : Aucune vulnÃ©rabilitÃ© critique

---

## ğŸ”§ Tests Backend

### ğŸ“± Tests API Devices
```bash
#!/bin/bash
# Tests API Devices

echo "ğŸ§ª Tests API Devices"
echo "==================="

BASE_URL="http://localhost:8000"

# Test 1: Liste des appareils
echo "ğŸ“± Test GET /api/devices/"
curl -s "$BASE_URL/api/devices/" | jq '.devices | length' > /dev/null
echo "âœ… Liste appareils OK"

# Test 2: DÃ©tails appareil
echo "ğŸ“± Test GET /api/devices/{id}"
DEVICE_ID=$(curl -s "$BASE_URL/api/devices/" | jq -r '.devices[0].id // "test"')
curl -s "$BASE_URL/api/devices/$DEVICE_ID" > /dev/null
echo "âœ… DÃ©tails appareil OK"

# Test 3: Actualisation
echo "ğŸ”„ Test POST /api/devices/refresh"
curl -s -X POST "$BASE_URL/api/devices/refresh" | jq '.message' > /dev/null
echo "âœ… Refresh appareils OK"

# Test 4: Wake-on-LAN (simulation)
echo "âš¡ Test POST /api/devices/wake"
curl -s -X POST "$BASE_URL/api/devices/wake" \
  -H "Content-Type: application/json" \
  -d '{"device_id":"test"}' > /dev/null 2>&1
echo "âœ… Wake-on-LAN endpoint OK"

# Test 5: Statistiques
echo "ğŸ“Š Test GET /api/devices/status/summary"
curl -s "$BASE_URL/api/devices/status/summary" | jq '.total' > /dev/null
echo "âœ… Statistiques appareils OK"

echo "ğŸ‰ Tests API Devices terminÃ©s"
```

### ğŸŒ Tests API Network
```bash
#!/bin/bash
# Tests API Network

echo "ğŸ§ª Tests API Network"
echo "==================="

BASE_URL="http://localhost:8000"

# Test 1: Dernier scan
echo "ğŸŒ Test GET /api/network/scan"
curl -s "$BASE_URL/api/network/scan" > /dev/null
echo "âœ… Dernier scan OK"

# Test 2: Nouveau scan
echo "ğŸ” Test POST /api/network/scan"
curl -s -X POST "$BASE_URL/api/network/scan" \
  -H "Content-Type: application/json" \
  -d '{"target":"192.168.1.0/24","fast":true}' > /dev/null
echo "âœ… Nouveau scan OK"

# Test 3: Historique
echo "ğŸ“ˆ Test GET /api/network/history"
curl -s "$BASE_URL/api/network/history?days=7" | jq '.history' > /dev/null
echo "âœ… Historique rÃ©seau OK"

# Test 4: Analyse
echo "ğŸ”¬ Test GET /api/network/analyze"
curl -s "$BASE_URL/api/network/analyze" > /dev/null
echo "âœ… Analyse rÃ©seau OK"

# Test 5: Topologie
echo "ğŸ—ºï¸ Test GET /api/network/topology"
curl -s "$BASE_URL/api/network/topology" | jq '.subnets' > /dev/null
echo "âœ… Topologie rÃ©seau OK"

# Test 6: Statistiques
echo "ğŸ“Š Test GET /api/network/stats"
curl -s "$BASE_URL/api/network/stats" > /dev/null
echo "âœ… Statistiques rÃ©seau OK"

echo "ğŸ‰ Tests API Network terminÃ©s"
```

### ğŸ”’ Tests API Tailscale
```bash
#!/bin/bash
# Tests API Tailscale

echo "ğŸ§ª Tests API Tailscale"
echo "====================="

BASE_URL="http://localhost:8000"

# Test 1: Configuration
echo "ğŸ”’ Test GET /api/tailscale/config"
curl -s "$BASE_URL/api/tailscale/config" | jq '.is_configured' > /dev/null
echo "âœ… Configuration Tailscale OK"

# Test 2: Appareils VPN
echo "ğŸ“± Test GET /api/tailscale/devices"
curl -s "$BASE_URL/api/tailscale/devices" > /dev/null 2>&1
echo "âœ… Appareils Tailscale OK"

# Test 3: Statut service
echo "ğŸ“Š Test GET /api/tailscale/status"
curl -s "$BASE_URL/api/tailscale/status" | jq '.is_configured' > /dev/null
echo "âœ… Statut Tailscale OK"

# Test 4: Test connexion
echo "ğŸ” Test POST /api/tailscale/test-connection"
curl -s -X POST "$BASE_URL/api/tailscale/test-connection" > /dev/null
echo "âœ… Test connexion Tailscale OK"

# Test 5: Cache clear
echo "ğŸ—‘ï¸ Test POST /api/tailscale/clear-cache"
curl -s -X POST "$BASE_URL/api/tailscale/clear-cache" > /dev/null
echo "âœ… Clear cache Tailscale OK"

echo "ğŸ‰ Tests API Tailscale terminÃ©s"
```

### ğŸ“Š Tests API Monitoring
```bash
#!/bin/bash
# Tests API Monitoring

echo "ğŸ§ª Tests API Monitoring"
echo "======================"

BASE_URL="http://localhost:8000"

# Test 1: Statistiques globales
echo "ğŸ“Š Test GET /api/monitoring/stats"
curl -s "$BASE_URL/api/monitoring/stats" | jq '.devices.total' > /dev/null
echo "âœ… Statistiques monitoring OK"

# Test 2: SantÃ© systÃ¨me
echo "ğŸ¥ Test GET /api/monitoring/health"
curl -s "$BASE_URL/api/monitoring/health" | jq '.overall' > /dev/null
echo "âœ… SantÃ© systÃ¨me OK"

# Test 3: Performance
echo "âš¡ Test GET /api/monitoring/performance"
curl -s "$BASE_URL/api/monitoring/performance" > /dev/null
echo "âœ… MÃ©triques performance OK"

# Test 4: ActivitÃ© rÃ©cente
echo "ğŸ“ˆ Test GET /api/monitoring/activity"
curl -s "$BASE_URL/api/monitoring/activity" | jq '.recent_scans' > /dev/null
echo "âœ… ActivitÃ© rÃ©cente OK"

# Test 5: Benchmark
echo "ğŸƒ Test POST /api/monitoring/benchmark"
curl -s -X POST "$BASE_URL/api/monitoring/benchmark" | jq '.total_time_ms' > /dev/null
echo "âœ… Benchmark systÃ¨me OK"

echo "ğŸ‰ Tests API Monitoring terminÃ©s"
```

### ğŸ”§ Tests API System
```bash
#!/bin/bash
# Tests API System

echo "ğŸ§ª Tests API System"
echo "=================="

BASE_URL="http://localhost:8000"

# Test 1: Statut systÃ¨me
echo "ğŸ”§ Test GET /api/system/status"
curl -s "$BASE_URL/api/system/status" | jq '.status' > /dev/null
echo "âœ… Statut systÃ¨me OK"

# Test 2: Logs systÃ¨me
echo "ğŸ“œ Test GET /api/system/logs"
curl -s "$BASE_URL/api/system/logs" | jq '.logs' > /dev/null
echo "âœ… Logs systÃ¨me OK"

# Test 3: Info Raspberry Pi
echo "ğŸ“ Test GET /api/system/raspberry"
curl -s "$BASE_URL/api/system/raspberry" | jq '.is_raspberry' > /dev/null
echo "âœ… Info Raspberry Pi OK"

# Test 4: Ping test
echo "ğŸ“ Test GET /api/system/ping/8.8.8.8"
curl -s "$BASE_URL/api/system/ping/8.8.8.8" | jq '.success' > /dev/null
echo "âœ… Ping test OK"

echo "ğŸ‰ Tests API System terminÃ©s"
```

---

## ğŸ¨ Tests Frontend

### ğŸ“± Tests Interface Web
```javascript
// Tests Frontend (Console navigateur)

console.log('ğŸ§ª Tests Frontend 333HOME');
console.log('==========================');

// Test 1: Chargement modules
try {
    if (window.app && window.app.dataManager) {
        console.log('âœ… DataManager chargÃ©');
    }
    if (window.app && window.app.deviceManager) {
        console.log('âœ… DeviceManager chargÃ©');
    }
    if (window.app && window.app.networkManager) {
        console.log('âœ… NetworkManager chargÃ©');
    }
    if (window.app && window.app.uiManager) {
        console.log('âœ… UIManager chargÃ©');
    }
} catch (error) {
    console.error('âŒ Erreur chargement modules:', error);
}

// Test 2: API Client
async function testAPIClient() {
    try {
        const status = await APIClient.get('/api/system/status');
        console.log('âœ… APIClient fonctionnel');
        return true;
    } catch (error) {
        console.error('âŒ APIClient dÃ©faillant:', error);
        return false;
    }
}

// Test 3: Navigation
function testNavigation() {
    try {
        const router = window.app.router;
        router.navigate('devices');
        router.navigate('network');
        router.navigate('dashboard');
        console.log('âœ… Navigation fonctionnelle');
        return true;
    } catch (error) {
        console.error('âŒ Navigation dÃ©faillante:', error);
        return false;
    }
}

// Test 4: Responsive design
function testResponsive() {
    try {
        // Simuler mobile
        window.innerWidth = 375;
        window.dispatchEvent(new Event('resize'));
        
        // VÃ©rifier menu mobile
        const sidebar = document.getElementById('sidebar');
        const isResponsive = sidebar && getComputedStyle(sidebar).position === 'fixed';
        
        // Restaurer desktop
        window.innerWidth = 1920;
        window.dispatchEvent(new Event('resize'));
        
        if (isResponsive) {
            console.log('âœ… Design responsive OK');
        } else {
            console.log('âš ï¸ Design responsive Ã  vÃ©rifier');
        }
        return isResponsive;
    } catch (error) {
        console.error('âŒ Test responsive Ã©chouÃ©:', error);
        return false;
    }
}

// ExÃ©cuter tous les tests
async function runAllFrontendTests() {
    console.log('ğŸš€ DÃ©marrage tests frontend...');
    
    const apiTest = await testAPIClient();
    const navTest = testNavigation();
    const respTest = testResponsive();
    
    const allPassed = apiTest && navTest && respTest;
    
    if (allPassed) {
        console.log('ğŸ‰ Tous les tests frontend passÃ©s!');
    } else {
        console.log('âš ï¸ Certains tests frontend ont Ã©chouÃ©');
    }
    
    return allPassed;
}

// Lancer les tests
runAllFrontendTests();
```

### ğŸ¨ Tests CSS et Responsive
```bash
#!/bin/bash
# Tests CSS et Responsive

echo "ğŸ§ª Tests CSS et Responsive"
echo "=========================="

# Test 1: Validation CSS
echo "ğŸ¨ Validation CSS..."
if command -v css-validator &> /dev/null; then
    css-validator web/static/css/main.css
    echo "âœ… CSS valide"
else
    echo "âš ï¸ css-validator non installÃ©"
fi

# Test 2: Taille des fichiers CSS
echo "ğŸ“ Taille fichiers CSS..."
find web/static/css -name "*.css" -exec ls -lh {} + | awk '{print $5 " " $9}'
echo "âœ… Tailles CSS vÃ©rifiÃ©es"

# Test 3: Variables CSS
echo "ğŸ¨ Variables CSS..."
grep -r "var(--" web/static/css/ | wc -l
echo "âœ… Variables CSS utilisÃ©es"

# Test 4: Media queries
echo "ğŸ“± Media queries..."
grep -r "@media" web/static/css/ | wc -l
echo "âœ… Media queries prÃ©sentes"

echo "ğŸ‰ Tests CSS terminÃ©s"
```

---

## âš¡ Tests de Performance

### ğŸš€ Test de Charge API
```bash
#!/bin/bash
# Tests de Performance API

echo "ğŸ§ª Tests de Performance"
echo "======================"

BASE_URL="http://localhost:8000"

# Test 1: Temps de rÃ©ponse endpoints
echo "âš¡ Temps de rÃ©ponse API..."

endpoints=(
    "/api/devices/"
    "/api/network/scan"
    "/api/monitoring/stats"
    "/api/system/status"
    "/api/tailscale/status"
)

for endpoint in "${endpoints[@]}"; do
    time_ms=$(curl -w "%{time_total}" -s -o /dev/null "$BASE_URL$endpoint")
    time_readable=$(echo "$time_ms * 1000" | bc | cut -d. -f1)
    
    if (( $(echo "$time_ms < 2.0" | bc -l) )); then
        echo "âœ… $endpoint: ${time_readable}ms"
    else
        echo "âš ï¸ $endpoint: ${time_readable}ms (lent)"
    fi
done

# Test 2: Charge simultanÃ©e
echo "ğŸ”¥ Test de charge simultanÃ©e..."
for i in {1..10}; do
    curl -s "$BASE_URL/api/devices/" > /dev/null &
done
wait
echo "âœ… Charge simultanÃ©e gÃ©rÃ©e"

# Test 3: MÃ©moire utilisÃ©e
echo "ğŸ’¾ Utilisation mÃ©moire..."
ps aux | grep "python.*app" | grep -v grep | awk '{print $4"%"}'
echo "âœ… MÃ©moire surveillÃ©e"

echo "ğŸ‰ Tests performance terminÃ©s"
```

### ğŸ“Š Benchmark Complet
```python
#!/usr/bin/env python3
# benchmark.py - Benchmark complet 333HOME

import time
import asyncio
import httpx
import psutil
import statistics

async def benchmark_api():
    """Benchmark complet de l'API"""
    
    print("ğŸ§ª Benchmark API 333HOME")
    print("========================")
    
    base_url = "http://localhost:8000"
    endpoints = [
        "/api/devices/",
        "/api/network/scan",
        "/api/monitoring/stats", 
        "/api/system/status",
        "/api/tailscale/status"
    ]
    
    async with httpx.AsyncClient() as client:
        # Test de chaque endpoint
        for endpoint in endpoints:
            times = []
            
            for _ in range(10):  # 10 requÃªtes par endpoint
                start = time.time()
                try:
                    response = await client.get(f"{base_url}{endpoint}")
                    end = time.time()
                    
                    if response.status_code == 200:
                        times.append((end - start) * 1000)  # ms
                    else:
                        print(f"âŒ {endpoint}: HTTP {response.status_code}")
                        
                except Exception as e:
                    print(f"âŒ {endpoint}: {str(e)}")
            
            if times:
                avg_time = statistics.mean(times)
                max_time = max(times)
                min_time = min(times)
                
                status = "âœ…" if avg_time < 2000 else "âš ï¸"
                print(f"{status} {endpoint}:")
                print(f"   Moyenne: {avg_time:.1f}ms")
                print(f"   Min: {min_time:.1f}ms")
                print(f"   Max: {max_time:.1f}ms")
        
        # Test de charge
        print("\nğŸ”¥ Test de charge (100 requÃªtes simultanÃ©es)...")
        start = time.time()
        
        tasks = []
        for _ in range(100):
            task = client.get(f"{base_url}/api/devices/")
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        end = time.time()
        
        success_count = sum(1 for r in responses if hasattr(r, 'status_code') and r.status_code == 200)
        total_time = end - start
        
        print(f"âœ… {success_count}/100 requÃªtes rÃ©ussies")
        print(f"âœ… Temps total: {total_time:.2f}s")
        print(f"âœ… DÃ©bit: {100/total_time:.1f} req/s")

def benchmark_system():
    """Benchmark systÃ¨me"""
    
    print("\nğŸ–¥ï¸ Benchmark SystÃ¨me")
    print("====================")
    
    # CPU
    cpu_percent = psutil.cpu_percent(interval=1)
    print(f"ğŸ’» CPU: {cpu_percent}%")
    
    # MÃ©moire
    memory = psutil.virtual_memory()
    print(f"ğŸ’¾ MÃ©moire: {memory.percent}% ({memory.used/1024**3:.1f}GB utilisÃ©s)")
    
    # Disque
    disk = psutil.disk_usage('/')
    print(f"ğŸ’¿ Disque: {disk.percent}% ({disk.free/1024**3:.1f}GB libres)")
    
    # Processus Python
    for proc in psutil.process_iter(['pid', 'name', 'memory_percent']):
        if 'python' in proc.info['name'].lower() and 'app' in ' '.join(proc.cmdline()):
            print(f"ğŸ Processus Python: PID {proc.info['pid']}, {proc.info['memory_percent']:.1f}% RAM")

if __name__ == "__main__":
    # Benchmark systÃ¨me
    benchmark_system()
    
    # Benchmark API
    asyncio.run(benchmark_api())
    
    print("\nğŸ‰ Benchmark terminÃ©!")
```

---

## ğŸ›¡ï¸ Tests de SÃ©curitÃ©

### ğŸ”’ Tests de SÃ©curitÃ© Basiques
```bash
#!/bin/bash
# Tests de SÃ©curitÃ©

echo "ğŸ§ª Tests de SÃ©curitÃ©"
echo "==================="

BASE_URL="http://localhost:8000"

# Test 1: Injection SQL (simulation)
echo "ğŸ”’ Test injection SQL..."
curl -s "$BASE_URL/api/devices/" \
  -G -d "filter='; DROP TABLE devices; --" > /dev/null
echo "âœ… Protection injection SQL"

# Test 2: XSS (simulation)
echo "ğŸ”’ Test XSS..."
curl -s "$BASE_URL/api/devices/" \
  -G -d "name=<script>alert('xss')</script>" > /dev/null
echo "âœ… Protection XSS"

# Test 3: Headers de sÃ©curitÃ©
echo "ğŸ”’ Headers de sÃ©curitÃ©..."
headers=$(curl -s -I "$BASE_URL/" | grep -i "x-")
if [[ -n "$headers" ]]; then
    echo "âœ… Headers sÃ©curitÃ© prÃ©sents"
else
    echo "âš ï¸ Headers sÃ©curitÃ© Ã  ajouter"
fi

# Test 4: HTTPS (si disponible)
echo "ğŸ”’ Test HTTPS..."
if curl -s "https://localhost:8000/" > /dev/null 2>&1; then
    echo "âœ… HTTPS disponible"
else
    echo "âš ï¸ HTTPS non configurÃ©"
fi

echo "ğŸ‰ Tests sÃ©curitÃ© terminÃ©s"
```

---

## ğŸ“‹ Suites de Tests ComplÃ¨tes

### ğŸª Master Test Suite
```bash
#!/bin/bash
# master_test.sh - Suite de tests complÃ¨te

echo "ğŸª MASTER TEST SUITE 333HOME"
echo "============================="

# Variables
PASS=0
FAIL=0
BASE_URL="http://localhost:8000"

# Fonction de test
run_test() {
    local test_name="$1"
    local test_command="$2"
    
    echo "ğŸ§ª $test_name..."
    if eval "$test_command" > /dev/null 2>&1; then
        echo "âœ… $test_name PASS"
        ((PASS++))
    else
        echo "âŒ $test_name FAIL"
        ((FAIL++))
    fi
}

# Tests infrastructure
echo "ğŸ—ï¸ Tests Infrastructure"
echo "======================="
run_test "Application dÃ©marrÃ©e" "curl -s $BASE_URL/api/system/status"
run_test "Fichiers statiques" "curl -s $BASE_URL/static/js/app.js"
run_test "Templates HTML" "curl -s $BASE_URL/"

# Tests API Backend
echo "ğŸ”§ Tests API Backend"
echo "==================="
run_test "API Devices" "curl -s $BASE_URL/api/devices/"
run_test "API Network" "curl -s $BASE_URL/api/network/scan"
run_test "API Monitoring" "curl -s $BASE_URL/api/monitoring/stats"
run_test "API System" "curl -s $BASE_URL/api/system/status"
run_test "API Tailscale" "curl -s $BASE_URL/api/tailscale/status"

# Tests Performance
echo "âš¡ Tests Performance"
echo "==================="
run_test "RÃ©ponse < 2s" "timeout 2s curl -s $BASE_URL/api/devices/"
run_test "MÃ©moire < 512MB" "ps -o pid,vsz,cmd | grep 'python.*app' | awk '{if(\$2<524288) exit 0; else exit 1}'"

# Tests SÃ©curitÃ©
echo "ğŸ”’ Tests SÃ©curitÃ©"
echo "================="
run_test "Pas d'erreur 500" "! curl -s $BASE_URL/api/devices/nonexistent | grep -q '500'"
run_test "Validation entrÃ©es" "curl -s '$BASE_URL/api/system/ping/invalid..input' | grep -q 'detail'"

# RÃ©sultats
echo ""
echo "ğŸ“Š RÃ‰SULTATS FINAUX"
echo "=================="
echo "âœ… Tests rÃ©ussis: $PASS"
echo "âŒ Tests Ã©chouÃ©s: $FAIL"
echo "ğŸ“ˆ Taux de rÃ©ussite: $(( PASS * 100 / (PASS + FAIL) ))%"

if [ $FAIL -eq 0 ]; then
    echo "ğŸ‰ TOUS LES TESTS PASSÃ‰S!"
    exit 0
else
    echo "âš ï¸ CERTAINS TESTS ONT Ã‰CHOUÃ‰"
    exit 1
fi
```

### ğŸ¤– Tests AutomatisÃ©s CI/CD
```yaml
# .github/workflows/test.yml
name: Tests 333HOME

on:
  push:
    branches: [ master, develop ]
  pull_request:
    branches: [ master ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Setup Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Start application
      run: |
        python app_new.py &
        sleep 10
    
    - name: Run tests
      run: |
        chmod +x tests/master_test.sh
        ./tests/master_test.sh
    
    - name: Performance benchmark
      run: |
        python tests/benchmark.py
```

---

## ğŸ“Š Reporting et MÃ©triques

### ğŸ“ˆ Dashboard de Tests
```html
<!-- test_dashboard.html -->
<!DOCTYPE html>
<html>
<head>
    <title>ğŸ§ª Dashboard Tests 333HOME</title>
    <style>
        .metric { display: inline-block; margin: 10px; padding: 20px; border: 1px solid #ccc; }
        .pass { background: #d4edda; }
        .fail { background: #f8d7da; }
        .warn { background: #fff3cd; }
    </style>
</head>
<body>
    <h1>ğŸ§ª Dashboard Tests 333HOME</h1>
    
    <div id="metrics">
        <div class="metric pass">
            <h3>âœ… Tests PassÃ©s</h3>
            <div id="pass-count">-</div>
        </div>
        
        <div class="metric fail">
            <h3>âŒ Tests Ã‰chouÃ©s</h3>
            <div id="fail-count">-</div>
        </div>
        
        <div class="metric warn">
            <h3>ğŸ“Š Performance</h3>
            <div id="perf-score">-</div>
        </div>
    </div>
    
    <div id="test-results"></div>
    
    <script>
        // Charger les rÃ©sultats de tests
        async function loadTestResults() {
            try {
                const response = await fetch('/api/monitoring/stats');
                const data = await response.json();
                
                // Simuler des mÃ©triques de test
                document.getElementById('pass-count').textContent = '42';
                document.getElementById('fail-count').textContent = '1';
                document.getElementById('perf-score').textContent = '95%';
                
            } catch (error) {
                console.error('Erreur chargement:', error);
            }
        }
        
        loadTestResults();
        setInterval(loadTestResults, 30000); // Refresh toutes les 30s
    </script>
</body>
</html>
```

---

**ğŸ“… Guide tests crÃ©Ã© :** 19 octobre 2025  
**ğŸ§ª Couverture :** Backend + Frontend + Performance + SÃ©curitÃ©  
**ğŸ¯ Objectif :** Validation complÃ¨te architecture modulaire  
**ğŸ¤– Automation :** Scripts prÃªts pour CI/CD